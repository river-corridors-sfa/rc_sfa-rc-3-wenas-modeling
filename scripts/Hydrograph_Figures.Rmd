---
title: "Hydrograph_Figures"
author: "AMP"
date: "`r Sys.Date()`"
output: html_document
---

## Set Up Your Environment 

Get ready to have a R party! 

```{r setup, include=FALSE}
 knitr::opts_chunk$set(echo = TRUE)

 # load packages
 require(pacman)
 pacman::p_load(tidyverse, # keep things tidy!!
                googlesheets4, # read_sheet
                googledrive, # google drive access
                ggplot2, #plotting
                PNWColors ) # pretty colors 

 #double check your wd. should be ../rc_sfa-rc-3-wenas-modeling/scripts
 #if not you need to do new relative file pathing!

 getwd()

```

## Load Model Outputs 

Read in Level 1 Datasets:

```{r load rds for all model outputs, echo = FALSE}

 # all_outputs_wmeta <- read_rds("./data/outputs/2023-10-05_output_datset_L1.rda") # no idea why this is giving me a directory error

load("~/GitHub/rc_sfa-rc-3-wenas-modeling/data/outputs/2023-10-05_output_datset_L1.rda")

```

## Select Scenario to plot

We are interested in looking at the  scenarios with a hydrograph display to show specific hydrograph case comparisons for the threshold behaviors in variables of interest.

Evan's Canyon Fire Info: 

https://inciweb.nwcg.gov/incident-information/wases-evans-canyon-fire

https://www.wsp.wa.gov/2020/09/01/state-fire-mobilization-authorized-for-the-evans-canyon-fire/

```{r}
percent_outputs <- outputs_final %>%
  filter(climate == "base" & land_use == "base" & hydrology == "base" & slope == "base") %>%
    mutate(severity = fct_relevel(severity, "HIGH","MOD","LOW", "base"),
           percent= fct_relevel(percent, "base", "10", "15", "20","25", "30", "40", "45", "50", "60", "75", "90", "100"))
```

## Plotting

```{r Plotting, echo=TRUE}
severity_colors_rev = c("#F21A00",  "#E1AF00",  "#3B9AB2","black")

fire_start = as.Date("2019-08-31") # model fire started in 2019 # 
#position= position_jitterdodge()

flow_hydrograph <- percent_outputs %>%
  ggplot() +
  geom_line(aes(x = dates, y=flow_m3s_fire, color= severity, linetype = percent), position = "dodge" , alpha = 0.5) +  
  scale_color_manual(values = severity_colors_rev)  +
  #scale_linetype_manual(values = c("solid", "longdash", "solid", "longdash"))+
  scale_linewidth(range = c(0.2, 1)) +
  geom_vline(xintercept = fire_start,linetype="dashed",color="maroon")+
  ylab("Flow (m3/s)")+
  xlab("Simulation Month")+
  scale_x_date(breaks= "2 months", date_labels = "%b")+
  theme_classic()+
  theme(legend.position = "bottom")+
  guides(color= guide_legend(nrow= 5))

flow_hydrograph

cowplot::save_plot("../figures/scenarios_hydrograph.jpeg", flow_hydrograph, base_height = 4, base_width = 8, dpi=600)

```

This is hard to look at so, try a different way to plot the data
Following:
https://vt-hydroinformatics.github.io/fdcs.html

```{r}
severity_colors = c("#3B9AB2", "#E1AF00", "#F21A00")

no_fire_flow <- percent_outputs %>%
  distinct(dates, .keep_all=TRUE) %>%
  select(dates, flow_m3s_nofire)


ecdf <- percent_outputs %>%
  group_by(short_scenario) %>%
  filter(!scenario == "base_burned") %>%
  filter(!percent == "base") %>%
  ggplot(aes(flow_m3s_fire, color= severity, linetype = percent, alpha = as.numeric(percent)))+
  stat_ecdf()+
  scale_x_log10()+
  geom_vline(xintercept = median(no_fire_flow$flow_m3s_nofire), color = "black")+
  geom_vline(xintercept = quantile(no_fire_flow$flow_m3s_nofire)[4], color = "black",linetype="dashed") +
  scale_color_manual(values = severity_colors_rev)+
  theme_classic() +
  facet_wrap(~factor(severity, level =c("LOW","MOD","HIGH")), nrow = 1, 
             labeller = label_wrap_gen(10))

ecdf
```
Calculate flow exceedence probabilities

```{r}
Qdat <- Qdat %>%
  mutate(rank = rank(-Flow)) %>%
  mutate(P = 100 * (rank / (length(Flow) + 1)))
```


### This is old code, don't run

- Run this chunk if you need to re-import the output scenarios, i.e. if they've changed etc. This is currently pulling from the New Model (DOC) folder updated May 12, 2023.

- If that's the current version of the model outputs you want, # comment this out, then go to the next chunk...
 
``` {r read in data, echo=FALSE}
 ## Set GDrive URL for files

#  directory = "https://drive.google.com/drive/folders/1tl1Kf0PxVHbS7wPL4W071pvS1Af3Ji1i"
# 
#  read_data <- function(data){
#    # First, scrape scenario name from file name
#    scenario <- stringr::word(data, sep= fixed(".c"))
#    # Second, read in data
#    read.csv(file = data) %>%
#      mutate(scenario = scenario)
#   }
# 
#  ## Create a list of files to download
#  # Grab the files that are the full simulation results, NOT the stat_summaries
#  files <- drive_ls(directory) %>%
#    filter(grepl("_results", name))
# 
#  ## Download files to local (don't worry, we'll delete 'em in a sec)
#  lapply(files$id, drive_download, overwrite = TRUE)
# 
#  ## Read in data
#  all_outputs <- files$name %>%
#    map(read_data) %>%
#    bind_rows()
# 
#  all_outputs$dates <- as.POSIXct(all_outputs$dates)
# 
#  key = googlesheets4::read_sheet("https://docs.google.com/spreadsheets/d/1fM_JKnCXQ9uUFaplQ90YwZevvnrnpSp_R26KsN8tHdM/edit#gid=0", sheet = 1)
# 
#  all_outputs_wmeta <- left_join(all_outputs, key, by=c("scenario"))
# 
#  ## Clean up local (delete downloaded files)
#  file.remove(c(files$name))
# 
# # Save the outputs as an rds file to easily load back in and not have to wait 5 minutes to download the datasets from Google Drive.
# 
# write_rds(all_outputs_wmeta, "../New_DOC_Model_Outputs_20230512_Combined_with_Metadata.rds")

```

flow_colors = c("#9C964A", "#2d2926", "#81a9ad", "#537380") 
flow_fire_colors= pnw_palette("Sunset", 3 , type = "discrete")
  #c("#02401B", "#81A88D", "#9C964A") #inspired by wesanderson R package
