---
title: "230705_watershed_figures"
author: "PR"
date: "2023-07-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, 
                      message = F, 
                      warning = F)
```

### Description

This markdown creates a figure for model outputs showing changes based on manipulating watershed characteristics. Fire severity model runs are incorporated into a different figure generated by a different script.  

**IMPORTANT: if source files change, change eval to TRUE for the `Pull data from G Drive` chunk to pull updated data!**

```{r Setup}
require(pacman)
p_load(tidyverse,
       PNWColors,
       plotly,
       cowplot,
       janitor, 
       googledrive)

## Set ggplot theme and color palette
theme_set(theme_bw())
color_scheme <- PNWColors::pnw_palette("Bay", 4)

## Set data path
path <- "https://drive.google.com/drive/folders/1tl1Kf0PxVHbS7wPL4W071pvS1Af3Ji1i"
local_path <- "data/new_model/"

## Set a standardized alpha value for all plots
set_alpha = 0.8
```

First up, let's download the data from Drive to local so we can work with it. We'll put it in pr_work/data/new_model. Note that I'm commenting this one out to speed up rerunning the script

```{r Pull data from G Drive, eval = F}

## Authorize GDrive
options(gargle_oauth_email = "peter.regier@pnnl.gov")

## Pull files
files <- drive_ls(path) %>% 
  filter(grepl("_summar", name)) %>% 
  filter(!grepl("_old", name))

## Download files to /data
for(i in 1:nrow(files)){
  drive_download(files$id[[i]], paste0(local_path, files$name[[i]]), overwrite = T)
}

print(paste(nrow(files), "files downloaded"))
```


Now that we've downloaded files, let's work up the data, and look at an initial plot. First, we remove files we won't use, including all the percentage burn runs, and all the *_nofire.csv files (legacy, not needed).

```{r Import data}

## Filter out all files with _PER_ which are burn severity files
watershed_files <- tibble(file = grep(list.files(path = local_path, full.names = F), pattern='_PER_', invert=TRUE, value=TRUE)) %>% 
  filter(!grepl("summaries_base|summaries_LOW|summaries_MOD|summaries_HIGH|_nofire", file)) 

## Now they're local, read them in and label em
read_medians <- function(file){
  read_csv(paste0(local_path, file)) %>%
    filter(metric == "median") %>%
    mutate(file_raw = file) %>%
    dplyr::select(file_raw, scenario, metric, flow, sed_con, nitrate_mgL, doc_mgL) %>%
    clean_names()
}

## This gives us a row for each severity, and by calling distinct at the end, we both ensure all base_unburned rows are equal, and remove all the duplicates
watershed_medians_raw <- watershed_files$file %>%
  map(read_medians) %>%
  bind_rows()

```

Next, we reformat our data so it's easier to calculate percentages.

```{r Format data for plotting}

## Filenames are a little complicated to parse, so let's sort that mess out
watershed_medians_long <- watershed_medians_raw %>% 
  mutate(file_trim = str_remove_all(file_raw, "stats_summaries_|_fire.csv|HRU_SLP_")) %>% 
  mutate(category = case_when(file_trim == "coniferous" | file_trim == "deciduous" | 
                                file_trim == "grass" ~ "land_cover",  file_trim == "shrub" ~ "land_cover", 
                              file_trim == "DRY" | file_trim == "WET" ~ "precipitation", 
                              file_trim == "GWQ" | file_trim == "LATQ" | file_trim == "SURQ" ~ "flowpath", 
                              TRUE ~ "slope")) %>% 
  mutate(fire = stringr::word(scenario, start = -1, sep = "_")) %>% 
  select(-c(scenario, metric, file_raw)) %>% 
  rename("scenario" = file_trim)

watershed_medians_wide <- watershed_medians_long %>%
  pivot_wider(names_from = fire, values_from = c(flow, sed_con, nitrate_mg_l, doc_mg_l)) 

plots1 <- function(var){
  ggplot(watershed_medians_long, aes(scenario, {{var}}, fill = fire)) + 
  geom_col(position = "dodge") + 
  facet_wrap(~category, scales = "free_x", nrow = 1)
}

plots1(flow)

```
Finally, percentages calculated as a standardized percent change calculation of **Percent Change: ( Burn - Original ) / Original * 100**

```{r Calculate % changes}

## Create a function to calculate percent change
percent_change = function(var, baseline){
  (({{var}} - {{baseline}}) / {{baseline}}) * 100
}

watershed_medians <- watershed_medians_wide %>% 
  mutate(flow_perc = percent_change(flow_fire, flow_nofire), 
         sed_perc = percent_change(sed_con_fire, sed_con_nofire), 
         nitrate_perc = percent_change(nitrate_mg_l_fire, nitrate_mg_l_nofire), 
         doc_perc = percent_change(doc_mg_l_fire, doc_mg_l_nofire)) %>% 
  select(scenario, category, contains("_perc"))

watershed_medians

```

Now let's plot the results:
```{r Make plots}

ggplot(watershed_medians, aes(flow_perc, scenario, fill = category)) + 
  geom_col() + 
  facet_wrap(~category, ncol= 1, scales = "free_y")

```

Something definitely seems off here, could be coding, data, or both. 


