---
title: "01_Wenas_meta"
output: html_document
date: "2023-09-06"
editor_options: 
  chunk_output_type: console
---

The purpose of this script is take the output from SCOPUS and Web of Science and merge them into 1 working document. 

## Load packages and set working directory
```{r Jake/Mac}
#for Jake/mac

rm(list=ls(all=T)) #this clears your Environment

library(readr)
library(tidyverse)
library(here)
library(readxl)
library(ggmap)
```


```{r merge web of science and Scopus results}
web_meta <- read_csv(here("inputs", "Metaanalysis_webofscience.csv"), skip = 10) # reading in web of science output

web_meta <-web_meta %>% 
  select(-("1900":"2023")) %>% 
  mutate_all(as.character) # removing columns that are not necessary. Column 1900:2023 are purely counting the amount of citations per year and I don't care for that. I am also making all columns characters so it will be easier to merge. 

scopus_meta <- read_csv(here("inputs", "Wenas_meta_analysis_scopus.csv")) # reading in the scopus output

scopus_meta <- scopus_meta %>% 
  mutate_all(as.character) # Changing all columns to characters so it will be easier to merge

merged_meta <- full_join(web_meta, scopus_meta) %>% 
  distinct(DOI, .keep_all = TRUE) # merging both dataframes and removing duplicated DOIs. This yields 319 studies. 

# export dataframe 
write_csv(merged_meta, here("Output_for_analysis", "merged_meta.csv")) # exporting merged dataframe into outputs file


```

```{r round 2 of filter, plot where the 1st round filter on a map to see if we should filter by geographic location}
library("rnaturalearth")
library("rnaturalearthdata")

meta <- read_excel(here("inputs", "StudiesData_Table1.xlsx"), 
    sheet = "Study_info_filtered_take_one") # reading in filtered meta data sheet

coords <- meta %>% 
  select(Lat, Long) %>% 
  mutate(across(everything(), as.numeric)) # creating dataframe that is just the coordinates

world <- ne_countries(scale = "medium", returnclass = "sf")
class(world)

ggplot(data = world) +
    geom_sf() +
    geom_point(data = coords, aes(x = Long, y = Lat), size = 4, 
        shape = 23, fill = "darkred") 

ggsave("meta_map_filter_1.pdf",
       path = here("initial_plots", "01_Wenas_meta_wrangle"),
       width = 8, height = 10, units = "in")

```


```{r Hampton Paper map script}
# HAMPTON paper # 
countries = map_data("world")
countriessub = subset(spData::world,name_long%in%c("United States","Canada","Australia","Spain","Portugal","South Africa"))

ariddata = read.csv("inputs/Aridity_Data.csv")

studymetalist = lapply(studies,function(x){
  read.csv(file.path(x))
})
Fig1sited = data.frame(do.call("rbind",lapply(1:length(studymetalist), function(x){
  # Extract latitude and longitude coordinates
  studysites=studymetalist[[x]][,
          c("Sub.area","Longitude","Latitude","Activity","X..Affected","Intensity","Burn.type","Slope....","Area..ha.",
            "Annual.Precipitation..cm.","Annual.Runoff..cm.","Frequency","Data.source","Data.Type"
            )]
  names(studysites)[1]="Site"
  studysites$Activity[studysites$Activity=="FALSE"]="F"
  sites = subset(studysites,!duplicated(Site))
  sites[,c("Annual.Precipitation..cm.","Annual.Runoff..cm.")] = 
    aggregate(studysites[,c("Annual.Precipitation..cm.","Annual.Runoff..cm.")],by=list(studysites$Site),FUN=mean,na.action=na.omit)[,-1]
  sites[,"X..Affected"] = sapply(sites$Site,function(ss){
    ssxa = subset(studysites,Site==ss)$X..Affected
    if(sum(!is.na(ssxa))!=0){return(max(ssxa,na.rm=T))}else{return(NA)}
    })
  sites = dplyr::left_join(sites,subset(ariddata,Study==studiesFINAL[x])[,c("Site","Aridity.Index")],
                    by=c("Site"))
  
  sites = cbind(data.frame(Study=studiesFINAL[x],sites))
  sites$Country = do.call("rbind",lapply(1:nrow(sites),function(s){
    pp = st_as_sf(st_sfc(st_point(as.vector(unlist(as.vector(sites[s,c("Longitude","Latitude")]))))),crs=4326)
    suppressMessages({suppressWarnings({
      st_intersection(pp,countriessub)$name_long
    })})
  }))
  sites = sites[,c("Study","Site","Longitude","Latitude","Country","Activity","X..Affected","Intensity","Burn.type","Slope....","Area..ha.",
                  "Annual.Precipitation..cm.","Annual.Runoff..cm.","Aridity.Index","Frequency","Data.source","Data.Type")]
  
  return(sites)
})))
write.csv(x = Fig1sited,file = "outdata/Fig1_site_metadata.csv")
Fig1sited$Intensity = factor(Fig1sited$Intensity,levels=c("L","M","H"))
Fig1sited$Burn.type = factor(Fig1sited$Burn.type,levels=c("N","P"))

sitesummary = do.call("rbind",lapply(1:5,function(c){
  col = c("Slope....","Area..ha.","Annual.Precipitation..cm.","Annual.Runoff..cm.","Aridity.Index")[c]
  name = c("Slope","Area (ha)","Precip (cm/yr)","Runoff (cm/yr)","Aridity Index")[c]
  cbind(data.frame(var = name),t(quantile(Fig1sited[,col],c(0,0.25,0.5,0.75,1),na.rm=T)))
  
}))
write.csv(x = sitesummary,file = "outdata/TableSI_2_SiteMetaData.csv")

```

















